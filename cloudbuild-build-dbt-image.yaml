steps:
  # Build DBT image
  - name: 'gcr.io/cloud-builders/docker'
    args: [
      'build',
      '-t', '${_REGION}-docker.pkg.dev/$PROJECT_ID/${_REPO_NAME}/dbt:${COMMIT_SHA}',
      '-t', '${_REGION}-docker.pkg.dev/$PROJECT_ID/${_REPO_NAME}/dbt:latest',
      '.'
    ]
    id: 'build-image'

  # Push to Artifact Registry
  - name: 'gcr.io/cloud-builders/docker'
    args: [
      'push', 
      '--all-tags',
      '${_REGION}-docker.pkg.dev/$PROJECT_ID/${_REPO_NAME}/dbt'
    ]
    id: 'push-image'

  # Update Airflow DAG with new image
  - name: 'gcr.io/cloud-builders/gcloud'
    entrypoint: 'bash'
    args:
      - '-c'
      - |
        # Mise à jour du fichier DAG avec la nouvelle image
        sed -i 's|image=".*"|image="${_REGION}-docker.pkg.dev/$PROJECT_ID/${_REPO_NAME}/dbt:${COMMIT_SHA}"|g' dags/dbt_dag.py
        
        # Upload du DAG mis à jour vers Cloud Composer
        gsutil cp dags/dbt_dag.py gs://$$COMPOSER_BUCKET/dags/
    env:
      - 'COMPOSER_BUCKET=${_COMPOSER_BUCKET}'
    id: 'update-dag'

  # Optionnel : Trigger the DAG run
  - name: 'gcr.io/cloud-builders/gcloud'
    args: [
      'composer', 'dags', 'trigger',
      '--environment', '${_COMPOSER_ENV}',
      '--location', '${_REGION}',
      'dbt_run_dag'
    ]
    id: 'trigger-dag'
    waitFor: ['update-dag']

# Substitutions for the build
substitutions:
  _REGION: 'europe-west1'
  _REPO_NAME: 'dbt-repo-${_ENVIRONMENT}'
  _ENVIRONMENT: 'dev'
  _COMPOSER_ENV: 'composer-dbt-${_ENVIRONMENT}'
  _COMPOSER_BUCKET: '${_COMPOSER_BUCKET_NAME}'

# Common environment variables
options:
  logging: CLOUD_LOGGING_ONLY
  machineType: 'E2_STANDARD_4'

timeout: '1200s'  # 20 minutes